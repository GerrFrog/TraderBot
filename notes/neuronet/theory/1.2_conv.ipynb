{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from binance.client import Client\n",
    "from binance.enums import *\n",
    "from keras.engine import sequential\n",
    "from keras.layers.recurrent import RNN\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import Dense, LSTM, Dropout, Bidirectional, GRU, ConvLSTM2D, Activation, CuDNNGRU, CuDNNLSTM, Conv2D, Conv1D, Input, MaxPooling1D, \\\n",
    "                         GlobalMaxPooling1D, Embedding\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, \\\n",
    "                                       EarlyStopping, LearningRateScheduler, \\\n",
    "                                       ReduceLROnPlateau, CSVLogger\n",
    "from tensorflow.keras.callbacks.experimental import BackupAndRestore\n",
    "from tensorflow.keras.metrics import Accuracy, BinaryAccuracy, \\\n",
    "                                     CategoricalAccuracy, \\\n",
    "                                     SparseCategoricalAccuracy, \\\n",
    "                                     TopKCategoricalAccuracy, \\\n",
    "                                     SparseTopKCategoricalAccuracy\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import keras\n",
    "import sys \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conv1D\n",
    "This layer creates a convolution kernel that is convolved with the layer input over a single spatial (or temporal) dimension to produce a tensor of outputs. If use_bias is True, a bias vector is created and added to the outputs. Finally, if activation is not None, it is applied to the outputs as well.<br>\n",
    "\n",
    "When using this layer as the first layer in a model, provide an input_shape argument (tuple of integers or None, e.g. (10, 128) for sequences of 10 vectors of 128-dimensional vectors, or (None, 128) for variable-length sequences of 128-dimensional vectors.<br>\n",
    "\n",
    "<center><img src=\"assets/conv1d.png\"></img></center>\n",
    "\n",
    "A convolution is the simple application of a filter to an input that results in an activation. Repeated application of the same filter to an input results in a map of activations called a feature map, indicating the locations and strength of a detected feature in an input, such as an image.<br>\n",
    "\n",
    "The innovation of convolutional neural networks is the ability to automatically learn a large number of filters in parallel specific to a training dataset under the constraints of a specific predictive modeling problem, such as image classification. The result is highly specific features that can be detected anywhere on input images.<br>\n",
    "\n",
    "<center><img src=\"assets/conv1d2.webp\"></img></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.layers.Conv1D(\n",
    "    filters=4,\n",
    "    kernel_size=600,\n",
    "    strides=1,\n",
    "    padding=\"valid\",\n",
    "    data_format=\"channels_last\",\n",
    "    dilation_rate=1,\n",
    "    groups=1,\n",
    "    activation=None,\n",
    "    use_bias=True,\n",
    "    kernel_initializer=\"glorot_uniform\",\n",
    "    bias_initializer=\"zeros\",\n",
    "    kernel_regularizer=None,\n",
    "    bias_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    kernel_constraint=None,\n",
    "    bias_constraint=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arguments\n",
    "- **filters:** Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution).\n",
    "- **kernel_size:** An integer or tuple/list of a single integer, specifying the length of the 1D convolution window.\n",
    "- **strides:** An integer or tuple/list of a single integer, specifying the stride length of the convolution. Specifying any stride value != 1 is incompatible with specifying any dilation_rate value != 1.\n",
    "- **padding:** One of \"valid\", \"same\" or \"causal\" (case-insensitive). \"valid\" means no padding. \"same\" results in padding with zeros evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input. \"causal\" results in causal (dilated) convolutions, e.g. output[t] does not depend on input[t+1:]. Useful when modeling temporal data where the model should not violate the temporal order. See WaveNet: A Generative Model for Raw Audio, section 2.1.\n",
    "- **data_format:** A string, one of channels_last (default) or channels_first.\n",
    "- **dilation_rate:** an integer or tuple/list of a single integer, specifying the dilation rate to use for dilated convolution. Currently, specifying any dilation_rate value != 1 is incompatible with specifying any strides value != 1.\n",
    "- **groups:** A positive integer specifying the number of groups in which the input is split along the channel axis. Each group is convolved separately with filters / groups filters. The output is the concatenation of all the groups results along the channel axis. Input channels and filters must both be divisible by groups.\n",
    "- **activation:** Activation function to use. If you don't specify anything, no activation is applied ( see keras.activations).\n",
    "- **use_bias:** Boolean, whether the layer uses a bias vector.\n",
    "- **kernel_initializer:** Initializer for the kernel weights matrix ( see keras.initializers). Defaults to 'glorot_uniform'.\n",
    "- **bias_initializer:** Initializer for the bias vector ( see keras.initializers). Defaults to 'zeros'.\n",
    "- **kernel_regularizer:** Regularizer function applied to the kernel weights matrix (see keras.regularizers).\n",
    "- **bias_regularizer:** Regularizer function applied to the bias vector ( see keras.regularizers).\n",
    "- **activity_regularizer:** Regularizer function applied to the output of the layer (its \"activation\") ( see keras.regularizers).\n",
    "- **kernel_constraint:** Constraint function applied to the kernel matrix ( see keras.constraints).\n",
    "- **bias_constraint:** Constraint function applied to the bias vector ( see keras.constraints)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consider only the top 10000 words\n",
    "max_words = 10000 \n",
    "\n",
    "text_input_layer = Input(shape=(500,))\n",
    "embedding_layer = Embedding(max_words, 50)(text_input_layer)\n",
    "text_layer = Conv1D(256, 3, activation='relu')(embedding_layer)\n",
    "text_layer = MaxPooling1D(3)(text_layer)\n",
    "text_layer = Conv1D(256, 3, activation='relu')(text_layer)\n",
    "text_layer = MaxPooling1D(3)(text_layer)\n",
    "text_layer = Conv1D(256, 3, activation='relu')(text_layer)\n",
    "text_layer = MaxPooling1D(3)(text_layer)\n",
    "text_layer = Conv1D(256, 3, activation='relu')(text_layer)\n",
    "text_layer = MaxPooling1D(3)(text_layer)\n",
    "text_layer = Conv1D(256, 3, activation='relu')(text_layer)\n",
    "text_layer = MaxPooling1D(3)(text_layer)\n",
    "text_layer = GlobalMaxPooling1D()(text_layer)\n",
    "text_layer = Dense(256, activation='relu')(text_layer)\n",
    "output_layer = Dense(1, activation='sigmoid')(text_layer)\n",
    "model = Model(text_input_layer, output_layer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Shape\n",
    "### 3+D tensor with shape: batch_shape + (steps, input_dim)<br>\n",
    "### input_shape=(batch, steps, channels)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Shape\n",
    "### 3+D tensor with shape: batch_shape + (new_steps, filters) steps value might have changed due to padding or strides.<br>\n",
    "### input_shape=(batch, new_steps, filters)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of 1D Convolutional Layer\n",
    "\n",
    "The first dimension refers to each input sample; in this case, we only have one sample. The second dimension refers to the length of each sample; in this case, the length is eight. The third dimension refers to the number of channels in each sample; in this case, we only have a single channel.<br>\n",
    "\n",
    "Therefore, the shape of the input array will be [1, 8, 1].<br>\n",
    "\n",
    "We will define a model that expects input samples to have the shape [8, 1].<br>\n",
    "\n",
    "The model will have a single filter with the shape of 3, or three elements wide. Keras refers to the shape of the filter as the kernel_size.<br>\n",
    "\n",
    "By default, the filters in a convolutional layer are initialized with random weights. In this contrived example, we will manually specify the weights for the single filter. We will define a filter that is capable of detecting bumps, that is a high input value surrounded by low input values, as we defined in our input example.<br>\n",
    "\n",
    "The weights must be specified in a three-dimensional structure, in terms of rows, columns, and channels. The filter has a single row, three columns, and one channel.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-08 02:52:11.573281: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-11-08 02:52:11.573325: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-11-08 02:52:11.573349: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (aspire): /proc/driver/nvidia/version does not exist\n",
      "2021-11-08 02:52:11.573735: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-08 02:52:11.691568: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[0.]],\n",
      "\n",
      "       [[1.]],\n",
      "\n",
      "       [[0.]]], dtype=float32), array([0.], dtype=float32)]\n",
      "[[[0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import asarray\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D\n",
    "# define input data\n",
    "data = asarray([0, 0, 0, 1, 1, 0, 0, 0])\n",
    "data = data.reshape(1, 8, 1)\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(1, 3, input_shape=(8, 1)))\n",
    "# define a vertical line detector\n",
    "weights = [asarray([[[0]],[[1]],[[0]]]), asarray([0.0])]\n",
    "# store the weights in the model\n",
    "model.set_weights(weights)\n",
    "# confirm they were stored\n",
    "print(model.get_weights())\n",
    "# apply filter to input data\n",
    "yhat = model.predict(data)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s take a closer look at what happened here.<br>\n",
    "\n",
    "Recall that the input is an eight element vector with the values: [0, 0, 0, 1, 1, 0, 0, 0].\n",
    "\n",
    "First, the three-element filter [0, 1, 0] was applied to the first three inputs of the input [0, 0, 0] by calculating the dot product (“.” operator), which resulted in a single output value in the feature map of zero.<br>\n",
    "\n",
    "Recall that a dot product is the sum of the element-wise multiplications, or here it is (0 x 0) + (1 x 0) + (0 x 0) = 0. In NumPy, this can be implemented manually as:\n",
    "```python\n",
    "from numpy import asarray\n",
    "print(asarray([0, 1, 0]).dot(asarray([0, 0, 0])))\n",
    "```\n",
    "\n",
    "In our manual example, this is as follows:<br>\n",
    "[0, 1, 0] . [0, 0, 0] = 0<br>\n",
    "\n",
    "The filter was then moved along one element of the input sequence and the process was repeated; specifically, the same filter was applied to the input sequence at indexes 1, 2, and 3, which also resulted in a zero output in the feature map.<br>\n",
    "[0, 1, 0] . [0, 0, 1] = 0<br>\n",
    "\n",
    "We are being systematic, so again, the filter is moved along one more element of the input and applied to the input at indexes 2, 3, and 4. This time the output is a value of one in the feature map. We detected the feature and activated appropriately.<br>\n",
    "[0, 1, 0] . [0, 1, 1] = 1<br>\n",
    "\n",
    "The process is repeated until we calculate the entire feature map.<br>\n",
    "[0, 0, 1, 1, 0, 0]<br>\n",
    "\n",
    "Note that the feature map has six elements, whereas our input has eight elements. This is an artefact of how the filter was applied to the input sequence. There are other ways to apply the filter to the input sequence that changes the shape of the resulting feature map, such as padding, but we will not discuss these methods in this post."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of 2D Convolutional Layer\n",
    "Again, we can constrain the input, in this case to a square 8×8 pixel input image with a single channel (e.g. grayscale) with a single vertical line in the middle.<br>\n",
    "\n",
    "The input to a Conv2D layer must be four-dimensional.<br>\n",
    "\n",
    "The first dimension defines the samples; in this case, there is only a single sample. The second dimension defines the number of rows; in this case, eight. The third dimension defines the number of columns, again eight in this case, and finally the number of channels, which is one in this case.<br>\n",
    "\n",
    "Therefore, the input must have the four-dimensional shape [samples, rows, columns, channels] or [1, 8, 8, 1] in this case.<br>\n",
    "\n",
    "The filter will be two-dimensional and square with the shape 3×3. The layer will expect input samples to have the shape [columns, rows, channels] or [8,8,1].<br>\n",
    "\n",
    "We will define a vertical line detector filter to detect the single vertical line in our input data.<br>\n",
    "\n",
    "The shape of the feature map output will be four-dimensional with the shape [batch, rows, columns, filters]. We will be performing a single batch and we have a single filter (one filter and one input channel), therefore the output shape is [1, ?, ?, 1]. We can pretty-print the content of the single feature map as follows.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[[0.]],\n",
      "\n",
      "        [[1.]],\n",
      "\n",
      "        [[0.]]],\n",
      "\n",
      "\n",
      "       [[[0.]],\n",
      "\n",
      "        [[1.]],\n",
      "\n",
      "        [[0.]]],\n",
      "\n",
      "\n",
      "       [[[0.]],\n",
      "\n",
      "        [[1.]],\n",
      "\n",
      "        [[0.]]]], dtype=float32), array([0.], dtype=float32)]\n",
      "[0.0, 0.0, 3.0, 3.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 3.0, 3.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 3.0, 3.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 3.0, 3.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 3.0, 3.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 3.0, 3.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "data = [[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0]]\n",
    "data = asarray(data)\n",
    "data = data.reshape(1, 8, 8, 1)\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(1, (3,3), input_shape=(8, 8, 1)))\n",
    "# define a vertical line detector\n",
    "detector = [[[[0]],[[1]],[[0]]],\n",
    "            [[[0]],[[1]],[[0]]],\n",
    "            [[[0]],[[1]],[[0]]]]\n",
    "weights = [asarray(detector), asarray([0.0])]\n",
    "# store the weights in the model\n",
    "model.set_weights(weights)\n",
    "# confirm they were stored\n",
    "print(model.get_weights())\n",
    "# apply filter to input data\n",
    "yhat = model.predict(data)\n",
    "for r in range(yhat.shape[1]):\n",
    "\t# print each column in the row\n",
    "\tprint([yhat[0,r,c,0] for c in range(yhat.shape[2])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s take a closer look at what was calculated.<br>\n",
    "\n",
    "First, the filter was applied to the top left corner of the image, or an image patch of 3×3 elements. Technically, the image patch is three dimensional with a single channel, and the filter has the same dimensions. We cannot implement this in NumPy using the dot() function, instead, we must use the tensordot() function so we can appropriately sum across all dimensions, for example:<br>\n",
    "```python\n",
    "from numpy import asarray\n",
    "from numpy import tensordot\n",
    "m1 = asarray([[0, 1, 0],\n",
    "\t\t\t  [0, 1, 0],\n",
    "\t\t\t  [0, 1, 0]])\n",
    "m2 = asarray([[0, 0, 0],\n",
    "\t\t\t  [0, 0, 0],\n",
    "\t\t\t  [0, 0, 0]])\n",
    "print(tensordot(m1, m2))\n",
    "```\n",
    "\n",
    "This calculation results in a single output value of 0.0, e.g., the feature was not detected. This gives us the first element in the top-left corner of the feature map.<br>\n",
    "\n",
    "Manually, this would be as follows:<br>\n",
    "```\n",
    "0, 1, 0     0, 0, 0\n",
    "0, 1, 0  .  0, 0, 0 = 0\n",
    "0, 1, 0     0, 0, 0\n",
    "```\n",
    "\n",
    "The filter is moved along one column to the left and the process is repeated. Again, the feature is not detected.<br>\n",
    "```\n",
    "0, 1, 0     0, 0, 1\n",
    "0, 1, 0  .  0, 0, 1 = 0\n",
    "0, 1, 0     0, 0, 1\n",
    "```\n",
    "\n",
    "One more move to the left to the next column and the feature is detected for the first time, resulting in a strong activation.<br>\n",
    "```\n",
    "0, 1, 0     0, 1, 1\n",
    "0, 1, 0  .  0, 1, 1 = 3\n",
    "0, 1, 0     0, 1, 1\n",
    "```\n",
    "\n",
    "This process is repeated until the edge of the filter rests against the edge or final column of the input image. This gives the last element in the first full row of the feature map.<br>\n",
    "```\n",
    "[0.0, 0.0, 3.0, 3.0, 0.0, 0.0]\n",
    "```\n",
    "\n",
    "The filter then moves down one row and back to the first column and the process is related from left to right to give the second row of the feature map. And on until the bottom of the filter rests on the bottom or last row of the input image.<br>\n",
    "\n",
    "Again, as with the previous section, we can see that the feature map is a 6×6 matrix, smaller than the 8×8 input image because of the limitations of how the filter can be applied to the input image.<br>\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
