{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-08 20:15:58.037544: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-11-08 20:15:58.037587: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from binance.client import Client\n",
    "from binance.enums import *\n",
    "from keras.engine import sequential\n",
    "from keras.layers.recurrent import RNN\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import Dense, LSTM, Dropout, Bidirectional, GRU, ConvLSTM2D, Activation, CuDNNGRU, CuDNNLSTM, Conv2D, Conv1D, Input, MaxPooling1D, \\\n",
    "                         GlobalMaxPooling1D, Embedding\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, \\\n",
    "                                       EarlyStopping, LearningRateScheduler, \\\n",
    "                                       ReduceLROnPlateau, CSVLogger\n",
    "from tensorflow.keras.callbacks.experimental import BackupAndRestore\n",
    "from tensorflow.keras.metrics import Accuracy, BinaryAccuracy, \\\n",
    "                                     CategoricalAccuracy, \\\n",
    "                                     SparseCategoricalAccuracy, \\\n",
    "                                     TopKCategoricalAccuracy, \\\n",
    "                                     SparseTopKCategoricalAccuracy\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import keras\n",
    "import sys \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pooling Layer\n",
    "Convolutional layers in a convolutional neural network summarize the presence of features in an input image.<br>\n",
    "\n",
    "A problem with the output feature maps is that they are sensitive to the location of the features in the input. One approach to address this sensitivity is to down sample the feature maps. This has the effect of making the resulting down sampled feature maps more robust to changes in the position of the feature in the image, referred to by the technical phrase “local translation invariance.”<br>\n",
    "\n",
    "Pooling layers provide an approach to down sampling feature maps by summarizing the presence of features in patches of the feature map. Two common pooling methods are average pooling and max pooling that summarize the average presence of a feature and the most activated presence of a feature respectively.\n",
    "- **Average Pooling:** Calculate the average value for each patch on the feature map.\n",
    "- **Maximum Pooling (or Max Pooling):** Calculate the maximum value for each patch of the feature map.\n",
    "\n",
    "The result of using a pooling layer and creating down sampled or pooled feature maps is a summarized version of the features detected in the input. They are useful as small changes in the location of the feature in the input detected by the convolutional layer will result in a pooled feature map with the feature in the same location. This capability added by pooling is called the model’s invariance to local translation.\n",
    "\n",
    "<center><img src=\"assets/pooling.png\"></img></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MaxPooling1D Layer\n",
    "Max pooling operation for 1D temporal data.<br>\n",
    "\n",
    "Downsamples the input representation by taking the maximum value over a spatial window of size pool_size. The window is shifted by strides. The resulting output, when using the \"valid\" padding option, has a shape of: output_shape = (input_shape - pool_size + 1) / strides)<br>\n",
    "\n",
    "The resulting output shape when using the \"same\" padding option is: output_shape = input_shape / strides<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.pooling.MaxPooling1D at 0x7f22f9b3c2e0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.layers.MaxPooling1D(\n",
    "    pool_size=2, strides=None, padding=\"valid\", data_format=\"channels_last\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arguments\n",
    "- **pool_size:** Integer, size of the max pooling window.\n",
    "- **strides:** Integer, or None. Specifies how much the pooling window moves for each pooling step. If None, it will default to pool_size.\n",
    "- **padding:** One of \"valid\" or \"same\" (case-insensitive). \"valid\" means no padding. \"same\" results in padding evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input.\n",
    "- **data_format:** A string, one of channels_last (default) or channels_first. The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape (batch, steps, features) while channels_first corresponds to inputs with shape (batch, features, steps)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Shape\n",
    "- If data_format='channels_last': 3D tensor with shape (batch_size, steps, features).\n",
    "- If data_format='channels_first': 3D tensor with shape (batch_size, features, steps).\n",
    "\n",
    "## Output Shape\n",
    "- If data_format='channels_last': 3D tensor with shape (batch_size, downsampled_steps, features).\n",
    "- If data_format='channels_first': 3D tensor with shape (batch_size, features, downsampled_steps)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "Maximum pooling, or max pooling, is a pooling operation that calculates the maximum, or largest, value in each patch of each feature map.<br>\n",
    "\n",
    "The results are down sampled or pooled feature maps that highlight the most present feature in the patch, not the average presence of the feature in the case of average pooling. This has been found to work better in practice than average pooling for computer vision tasks like image classification.<br>\n",
    "\n",
    "We can make the max pooling operation concrete by again applying it to the output feature map of the line detector convolutional operation and manually calculate the first row of the pooled feature map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 6, 6, 1)           10        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 3, 3, 1)           0         \n",
      "=================================================================\n",
      "Total params: 10\n",
      "Trainable params: 10\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[0.0, 3.0, 0.0]\n",
      "[0.0, 3.0, 0.0]\n",
      "[0.0, 3.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "from numpy import asarray\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "# define input data\n",
    "data = [[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0]]\n",
    "data = asarray(data)\n",
    "data = data.reshape(1, 8, 8, 1)\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(1, (3,3), activation='relu', input_shape=(8, 8, 1)))\n",
    "model.add(MaxPooling2D())\n",
    "# summarize model\n",
    "model.summary()\n",
    "# define a vertical line detector\n",
    "detector = [[[[0]],[[1]],[[0]]],\n",
    "            [[[0]],[[1]],[[0]]],\n",
    "            [[[0]],[[1]],[[0]]]]\n",
    "weights = [asarray(detector), asarray([0.0])]\n",
    "# store the weights in the model\n",
    "model.set_weights(weights)\n",
    "# apply filter to input data\n",
    "yhat = model.predict(data)\n",
    "# enumerate rows\n",
    "for r in range(yhat.shape[1]):\n",
    "\t# print each column in the row\n",
    "\tprint([yhat[0,r,c,0] for c in range(yhat.shape[2])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AveragePooling1D Layer\n",
    "Average pooling for temporal data.<br>\n",
    "\n",
    "Downsamples the input representation by taking the average value over the window defined by pool_size. The window is shifted by strides. The resulting output when using \"valid\" padding option has a shape of: output_shape = (input_shape - pool_size + 1) / strides)<br>\n",
    "\n",
    "The resulting output shape when using the \"same\" padding option is: output_shape = input_shape / strides<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.pooling.AveragePooling1D at 0x7f222a3e70d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.layers.AveragePooling1D(\n",
    "    pool_size=2, strides=None, padding=\"valid\", data_format=\"channels_last\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arguments\n",
    "- **pool_size:** Integer, size of the average pooling windows.\n",
    "- **strides:** Integer, or None. Factor by which to downscale. E.g. 2 will halve the input. If None, it will default to pool_size.\n",
    "- **padding:** One of \"valid\" or \"same\" (case-insensitive). \"valid\" means no padding. \"same\" results in padding evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input.\n",
    "- **data_format:** A string, one of channels_last (default) or channels_first. The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape (batch, steps, features) while channels_first corresponds to inputs with shape (batch, features, steps)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input shape\n",
    "- If data_format='channels_last': 3D tensor with shape (batch_size, steps, features).\n",
    "- If data_format='channels_first': 3D tensor with shape (batch_size, features, steps).\n",
    "\n",
    "## Output shape\n",
    "- If data_format='channels_last': 3D tensor with shape (batch_size, downsampled_steps, features).\n",
    "- If data_format='channels_first': 3D tensor with shape (batch_size, features, downsampled_steps)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "On two-dimensional feature maps, pooling is typically applied in 2×2 patches of the feature map with a stride of (2,2).<br>\n",
    "\n",
    "Average pooling involves calculating the average for each patch of the feature map. This means that each 2×2 square of the feature map is down sampled to the average value in the square.<br>\n",
    "\n",
    "For example, the output of the line detector convolutional filter in the previous section was a 6×6 feature map. We can look at applying the average pooling operation to the first line of that feature map manually.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-08 20:23:29.560582: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-11-08 20:23:29.560636: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-11-08 20:23:29.560665: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (aspire): /proc/driver/nvidia/version does not exist\n",
      "2021-11-08 20:23:29.561915: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-08 20:23:29.714140: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 6, 6, 1)           10        \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 3, 3, 1)           0         \n",
      "=================================================================\n",
      "Total params: 10\n",
      "Trainable params: 10\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[0.0, 3.0, 0.0]\n",
      "[0.0, 3.0, 0.0]\n",
      "[0.0, 3.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "from numpy import asarray\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import AveragePooling2D\n",
    "# define input data\n",
    "data = [[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0]]\n",
    "data = asarray(data)\n",
    "data = data.reshape(1, 8, 8, 1)\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(1, (3,3), activation='relu', input_shape=(8, 8, 1)))\n",
    "model.add(AveragePooling2D())\n",
    "# summarize model\n",
    "model.summary()\n",
    "# define a vertical line detector\n",
    "detector = [[[[0]],[[1]],[[0]]],\n",
    "            [[[0]],[[1]],[[0]]],\n",
    "            [[[0]],[[1]],[[0]]]]\n",
    "weights = [asarray(detector), asarray([0.0])]\n",
    "# store the weights in the model\n",
    "model.set_weights(weights)\n",
    "# apply filter to input data\n",
    "yhat = model.predict(data)\n",
    "# enumerate rows\n",
    "for r in range(yhat.shape[1]):\n",
    "\t# print each column in the row\n",
    "\tprint([yhat[0,r,c,0] for c in range(yhat.shape[2])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GlobalPooling1D Layer\n",
    "Downsamples the input representation by taking the maximum value over the time dimension.\n",
    "\n",
    "Instead of down sampling patches of the input feature map, global pooling down samples the entire feature map to a single value. This would be the same as setting the pool_size to the size of the input feature map.<br>\n",
    "\n",
    "Global pooling can be used in a model to aggressively summarize the presence of a feature in an image. It is also sometimes used in models as an alternative to using a fully connected layer to transition from feature maps to an output prediction for the model.<br>\n",
    "\n",
    "Both global average pooling and global max pooling are supported by Keras via the GlobalAveragePooling2D and GlobalMaxPooling2D classes respectively.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.pooling.GlobalMaxPooling1D at 0x7f22281a9a30>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.layers.GlobalMaxPooling1D(\n",
    "    data_format=\"channels_last\", keepdims=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arguments\n",
    "- **data_format:** A string, one of channels_last (default) or channels_first. The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape (batch, steps, features) while channels_first corresponds to inputs with shape (batch, features, steps).\n",
    "- **keepdims:** A boolean, whether to keep the temporal dimension or not. If keepdims is False (default), the rank of the tensor is reduced for spatial dimensions. If keepdims is True, the temporal dimension are retained with length 1. The behavior is the same as for tf.reduce_max or np.max."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Shape\n",
    "- If data_format='channels_last': 3D tensor with shape: (batch_size, steps, features)\n",
    "- If data_format='channels_first': 3D tensor with shape: (batch_size, features, steps)\n",
    "\n",
    "## Output Shape\n",
    "- If keepdims=False: 2D tensor with shape (batch_size, features).\n",
    "- If keepdims=True:\n",
    "    - If data_format='channels_last': 3D tensor with shape (batch_size, 1, features)\n",
    "    - If data_format='channels_first': 3D tensor with shape (batch_size, features, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 6, 6, 1)           10        \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d (Global (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 10\n",
      "Trainable params: 10\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[[3.]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import asarray\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "# define input data\n",
    "data = [[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0]]\n",
    "data = asarray(data)\n",
    "data = data.reshape(1, 8, 8, 1)\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(1, (3,3), activation='relu', input_shape=(8, 8, 1)))\n",
    "model.add(GlobalMaxPooling2D())\n",
    "# summarize model\n",
    "model.summary()\n",
    "# # define a vertical line detector\n",
    "detector = [[[[0]],[[1]],[[0]]],\n",
    "            [[[0]],[[1]],[[0]]],\n",
    "            [[[0]],[[1]],[[0]]]]\n",
    "weights = [asarray(detector), asarray([0.0])]\n",
    "# store the weights in the model\n",
    "model.set_weights(weights)\n",
    "# apply filter to input data\n",
    "yhat = model.predict(data)\n",
    "# enumerate rows\n",
    "print(yhat)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
