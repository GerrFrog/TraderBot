{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-08 01:43:21.572589: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-11-08 01:43:21.572614: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from binance.client import Client\n",
    "from binance.enums import *\n",
    "from keras.engine import sequential\n",
    "from keras.layers.recurrent import RNN\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, LSTM, Dropout, Bidirectional, GRU, ConvLSTM2D, Activation, CuDNNGRU, CuDNNLSTM, Conv2D\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, \\\n",
    "                                       EarlyStopping, LearningRateScheduler, \\\n",
    "                                       ReduceLROnPlateau, CSVLogger\n",
    "from tensorflow.keras.callbacks.experimental import BackupAndRestore\n",
    "from tensorflow.keras.metrics import Accuracy, BinaryAccuracy, \\\n",
    "                                     CategoricalAccuracy, \\\n",
    "                                     SparseCategoricalAccuracy, \\\n",
    "                                     TopKCategoricalAccuracy, \\\n",
    "                                     SparseTopKCategoricalAccuracy\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import keras\n",
    "import sys \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM\n",
    "Based on available runtime hardware and constraints, this layer will choose different implementations (cuDNN-based or pure-TensorFlow) to maximize the performance. If a GPU is available and all the arguments to the layer meet the requirement of the CuDNN kernel (see below for details), the layer will use a fast cuDNN implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize model\n",
    "model = Sequential()\n",
    "#LSTM layer\n",
    "model.add(LSTM(units=50, return_sequences=True,input_shape=(x_train.shape[1],1)))\n",
    "#Dropout layer\n",
    "model.add(Dropout(.2))\n",
    "#LSTM layer\n",
    "model.add(LSTM(units=50, return_sequences=False))\n",
    "#Dropout layer\n",
    "model.add(Dropout(.2))\n",
    "#Fully connected layer\n",
    "model.add(Dense(units=1))\n",
    "#Model compilation\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The architecture model above\n",
    "<center><img src=\"assets/lstm3.png\"></img></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.recurrent_v2.LSTM at 0x7f86dc0c2130>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.layers.LSTM(\n",
    "    units=1,\n",
    "    activation=\"tanh\",\n",
    "    recurrent_activation=\"sigmoid\",\n",
    "    use_bias=True,\n",
    "    kernel_initializer=\"glorot_uniform\",\n",
    "    recurrent_initializer=\"orthogonal\",\n",
    "    bias_initializer=\"zeros\",\n",
    "    unit_forget_bias=True,\n",
    "    kernel_regularizer=None,\n",
    "    recurrent_regularizer=None,\n",
    "    bias_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    kernel_constraint=None,\n",
    "    recurrent_constraint=None,\n",
    "    bias_constraint=None,\n",
    "    dropout=0.0,\n",
    "    recurrent_dropout=0.0,\n",
    "    return_sequences=False,\n",
    "    return_state=False,\n",
    "    go_backwards=False,\n",
    "    stateful=False,\n",
    "    time_major=False,\n",
    "    unroll=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arguments\n",
    "- **units:** Positive integer, dimensionality of the output space.\n",
    "- **activation:** Activation function to use. Default: hyperbolic tangent (tanh). If you pass None, no activation is applied (ie. \"linear\" activation: a(x) = x).\n",
    "- **recurrent_activation:** Activation function to use for the recurrent step. Default: sigmoid (sigmoid). If you pass None, no activation is applied (ie. \"linear\" activation: a(x) = x).\n",
    "- **use_bias:** Boolean (default True), whether the layer uses a bias vector.\n",
    "- **kernel_initializer:** Initializer for the kernel weights matrix, used for the linear transformation of the inputs. Default: glorot_uniform.\n",
    "- **recurrent_initializer:** Initializer for the recurrent_kernel weights matrix, used for the linear transformation of the recurrent state. Default: orthogonal.\n",
    "- **bias_initializer:** Initializer for the bias vector. Default: zeros.\n",
    "- **unit_forget_bias:** Boolean (default True). If True, add 1 to the bias of the forget gate at initialization. Setting it to true will also force bias_initializer=\"zeros\". This is recommended in Jozefowicz et al..\n",
    "- **kernel_regularizer:** Regularizer function applied to the kernel weights matrix. Default: None.\n",
    "- **recurrent_regularizer:** Regularizer function applied to the recurrent_kernel weights matrix. Default: None.\n",
    "- **bias_regularizer:** Regularizer function applied to the bias vector. Default: None.\n",
    "- **activity_regularizer:** Regularizer function applied to the output of the layer (its \"activation\"). Default: None.\n",
    "- **kernel_constraint:** Constraint function applied to the kernel weights matrix. Default: None.\n",
    "- **recurrent_constraint:** Constraint function applied to the recurrent_kernel weights matrix. Default: None.\n",
    "- **bias_constraint:** Constraint function applied to the bias vector. Default: None.\n",
    "- **dropout:** Float between 0 and 1. Fraction of the units to drop for the linear transformation of the inputs. Default: 0.\n",
    "- **recurrent_dropout:** Float between 0 and 1. Fraction of the units to drop for the linear transformation of the recurrent state. Default: 0.\n",
    "- **return_sequences:** Boolean. Whether to return the last output. in the output sequence, or the full sequence. Default: False.\n",
    "- **return_state:** Boolean. Whether to return the last state in addition to the output. Default: False.\n",
    "- **go_backwards:** Boolean (default False). If True, process the input sequence backwards and return the reversed sequence.\n",
    "- **stateful:** Boolean (default False). If True, the last state for each sample at index i in a batch will be used as initial state for the sample of index i in the following batch.\n",
    "- **time_major:** The shape format of the inputs and outputs tensors. If True, the inputs and outputs will be in shape [timesteps, batch, feature], whereas in the False case, it will be [batch, timesteps, feature]. Using time_major = True is a bit more efficient because it avoids transposes at the beginning and end of the RNN calculation. However, most TensorFlow data is batch-major, so by default this function accepts input and emits output in batch-major form.\n",
    "- **unroll:** Boolean (default False). If True, the network will be unrolled, else a symbolic loop will be used. Unrolling can speed-up a RNN, although it tends to be more memory-intensive. Unrolling is only suitable for short sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Shape\n",
    "The input to every LSTM layer must be three-dimensional. The three dimensions of this input are:\n",
    "- **Samples:** One sequence is one sample. A batch is comprised of one or more samples.\n",
    "- **Time Steps:** One time step is one point of observation in the sample.\n",
    "- **Features:** One feature is one observation at a time step.\n",
    "This means that the input layer expects a 3D array of data when fitting the model and when making predictions, even if specific dimensions of the array contain a single value, e.g. one sample or one feature.<br>\n",
    "\n",
    "When defining the input layer of your LSTM network, the network assumes you have 1 or more samples and requires that you specify the number of time steps and the number of features. You can do this by specifying a tuple to the “input_shape” argument.<br>\n",
    "\n",
    "For example, the model below defines an input layer that expects 1 or more samples, 50 time steps, and 2 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-08 01:26:18.047750: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-11-08 01:26:18.047780: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-11-08 01:26:18.047797: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (aspire): /proc/driver/nvidia/version does not exist\n",
      "2021-11-08 01:26:18.048073: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(50, 2)))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You always have to give a three-dimensional array as an input to your LSTM network (refer to the above image).<br>\n",
    "\n",
    "Where the first dimension represents the batch size, the second dimension represents the number of time-steps you are feeding a sequence. And the third dimension represents the number of units in one input sequence. For example, input shape looks like (batch_size, time_steps, seq_len).\n",
    "\n",
    "<center><img src=\"assets/lstm2.png\"></img></center><br><br>\n",
    "\n",
    "Also you can give any size for a batch.<br>\n",
    "You can also give an argument called batch_input_shape instead of input_shape. The difference here is that you have to give a fixed batch size now and your input array shape will look like (8,2,10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-08 01:43:27.746051: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-11-08 01:43:27.746082: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-11-08 01:43:27.746110: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (aspire): /proc/driver/nvidia/version does not exist\n",
      "2021-11-08 01:43:27.746462: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.LSTM(units=3, batch_input_shape=(8,2,10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, look at the other argument which is return_sequences.<br>\n",
    "\n",
    "This argument tells Whether to return the output at each time steps instead of the final time step. Now the output shape is 3D array, not a 2D array. And the shape of the array is (8,2,3). You can see that there is one extra dimension in between which represent number of time steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (8, 3)                    168       \n",
      "=================================================================\n",
      "Total params: 168\n",
      "Trainable params: 168\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (8, 2, 3)                 168       \n",
      "=================================================================\n",
      "Total params: 168\n",
      "Trainable params: 168\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.LSTM(units=3, batch_input_shape=(8,2,10), return_sequences=False))\n",
    "model.summary()\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.LSTM(units=3, batch_input_shape=(8,2,10), return_sequences=True))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of LSTM With Single Input Sample\n",
    "For example, this could be a sequence of 10 values.<br>\n",
    "\n",
    "We can then use the reshape() function on the NumPy array to reshape this one-dimensional array into a three-dimensional array with 1 sample, 10 time steps, and 1 feature at each time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10, 1)\n",
      "[[[0.1]\n",
      "  [0.2]\n",
      "  [0.3]\n",
      "  [0.4]\n",
      "  [0.5]\n",
      "  [0.6]\n",
      "  [0.7]\n",
      "  [0.8]\n",
      "  [0.9]\n",
      "  [1. ]]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "\n",
    "data = array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "data = data.reshape((1, 10, 1))\n",
    "\n",
    "print(data.shape)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of LSTM with Multiple Input Features\n",
    "For example, this could be two parallel series of 10 values.<br>\n",
    "\n",
    "This data can be framed as 1 sample with 10 time steps and 2 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10, 2)\n",
      "[[[0.1 1. ]\n",
      "  [0.2 0.9]\n",
      "  [0.3 0.8]\n",
      "  [0.4 0.7]\n",
      "  [0.5 0.6]\n",
      "  [0.6 0.5]\n",
      "  [0.7 0.4]\n",
      "  [0.8 0.3]\n",
      "  [0.9 0.2]\n",
      "  [1.  0.1]]]\n"
     ]
    }
   ],
   "source": [
    "data = array([\n",
    "\t[0.1, 1.0],\n",
    "\t[0.2, 0.9],\n",
    "\t[0.3, 0.8],\n",
    "\t[0.4, 0.7],\n",
    "\t[0.5, 0.6],\n",
    "\t[0.6, 0.5],\n",
    "\t[0.7, 0.4],\n",
    "\t[0.8, 0.3],\n",
    "\t[0.9, 0.2],\n",
    "\t[1.0, 0.1]])\n",
    "\n",
    "data = data.reshape(1, 10, 2)\n",
    "\n",
    "print(data.shape)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "- The input of the LSTM is always is a 3D array. (batch_size, time_steps, seq_len).\n",
    "- The output of the LSTM could be a 2D array or 3D array depending upon the return_sequences argument.\n",
    "- If return_sequence is False, the output is a 2D array. (batch_size, units)\n",
    "- If return_sequence is True, the output is a 3D array. batch_size, time_steps, units)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
